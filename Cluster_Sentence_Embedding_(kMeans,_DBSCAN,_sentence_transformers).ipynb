{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cluster Sentence Embedding (kMeans, DBSCAN, sentence-transformers).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeihkStRxRyGtEAGFUTMPZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raymondwcs/learning_bert/blob/master/Cluster_Sentence_Embedding_(kMeans%2C_DBSCAN%2C_sentence_transformers).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axSRYWSicNeN"
      },
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wrrWqI_ccPW"
      },
      "source": [
        "# from transformers import AutoModel, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# CHECKPOINT = 'bert-base-chinese'\n",
        "CHECKPOINT = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
        "\n",
        "MAX_LENGTH = 80\n",
        "\n",
        "# corpus = [\n",
        "#   \"Vodafone Wins ₹20,000 Crore Tax Arbitration Case Against Government\",\n",
        "#   \"Voda Idea shares jump nearly 15% as Vodafone wins retro tax case in Hague\",\n",
        "#   \"Gold prices today fall for 4th time in 5 days, down ₹6500 from last month high\",\n",
        "#   \"Silver futures slip 0.36% to Rs 59,415 per kg, down over 12% this week\",\n",
        "#   \"Amazon unveils drone that films inside your home. What could go wrong?\",\n",
        "#   \"IPHONE 12 MINI PERFORMANCE MAY DISAPPOINT DUE TO THE APPLE B14 CHIP\",\n",
        "#   \"Delhi Capitals vs Chennai Super Kings: Prithvi Shaw shines as DC beat CSK to post second consecutive win in IPL\",\n",
        "#   \"French Open 2020: Rafael Nadal handed tough draw in bid for record-equaling 20th Grand Slam\"\n",
        "# ]\n",
        "\n",
        "corpus = [\n",
        "  '這個服務生很不親切',         \n",
        "  '这个服务生很不亲切', \n",
        "  '黄昏時滂沱大雨',  \n",
        "  '放工時下大雨',\n",
        "  '這個週末陽光普照!',\n",
        "  '天朗氣清的星期天。',\n",
        "  '現時恒指已跌穿重要支持位26500點來看。',\n",
        "  '港股繼續尋底的機會是頗高的。'         \n",
        "]\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "# model = AutoModel.from_pretrained(CHECKPOINT)\n",
        "\n",
        "# tokens = tokenizer(text=corpus, max_length=MAX_LENGTH, add_special_tokens=True, padding='max_length', truncation=True, return_tensors='pt')\n",
        "# output = model(**tokens)\n",
        "\n",
        "corpus_embeddings = []\n",
        "# for i in range(len(output.pooler_output)):\n",
        "#   corpus_embeddings.append(output.pooler_output[i].detach().numpy())\n",
        "\n",
        "embedder = SentenceTransformer(CHECKPOINT)\n",
        "corpus_embeddings = embedder.encode(corpus)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK6r2Ua-vo8v"
      },
      "source": [
        "# Mesaure Embeddings Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIoNU5oru6RP",
        "outputId": "df401d55-f689-4fbb-de17-fa7ec87a507a"
      },
      "source": [
        "similarities = cosine_similarity(corpus_embeddings)\n",
        "similarities_sorted = similarities.argsort()\n",
        "id_1 = []\n",
        "id_2 = []\n",
        "score = []\n",
        "for index,array in enumerate(similarities_sorted):\n",
        "    id_1.append(index)\n",
        "    id_2.append(array[-2])\n",
        "    score.append(similarities[index][array[-2]])\n",
        "index_df = pd.DataFrame({'id_1' : id_1,\n",
        "                          'id_2' : id_2,\n",
        "                          'score' : score})\n",
        "\n",
        "print(index_df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id_1  id_2     score\n",
            "0     0     1  0.980593\n",
            "1     1     0  0.980593\n",
            "2     2     3  0.867589\n",
            "3     3     2  0.867589\n",
            "4     4     5  0.719055\n",
            "5     5     4  0.719055\n",
            "6     6     2  0.211332\n",
            "7     7     4  0.296934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul5-9_b-utoc"
      },
      "source": [
        "# K-Means Clustering (distance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXesFBH5ez1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48b8d97-16c2-43f2-905f-9c8b497d3678"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 4\n",
        "# Define kmeans model\n",
        "clustering_model = KMeans(n_clusters=num_clusters)\n",
        "# Fit the embedding with kmeans clustering.\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "# Get the cluster id assigned to each news headline.\n",
        "cluster_assignment = clustering_model.labels_\n",
        "\n",
        "print(cluster_assignment)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 2 2 1 1 2 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbNfU733iFOm",
        "outputId": "e42c1244-75b5-4fae-b3ee-3c4b1a87ef36"
      },
      "source": [
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster  1\n",
            "['這個服務生很不親切', '这个服务生很不亲切']\n",
            "\n",
            "Cluster  2\n",
            "['這個週末陽光普照!', '天朗氣清的星期天。']\n",
            "\n",
            "Cluster  3\n",
            "['黄昏時滂沱大雨', '放工時下大雨', '現時恒指已跌穿重要支持位26500點來看。']\n",
            "\n",
            "Cluster  4\n",
            "['港股繼續尋底的機會是頗高的。']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuFMgl8awZx3"
      },
      "source": [
        "# K-Means Clustering (similarity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkhJ5IMEsh2m",
        "outputId": "35187779-547f-481c-9c67-824f547e641b"
      },
      "source": [
        "import nltk\n",
        "from nltk.cluster.kmeans import KMeansClusterer\n",
        "num_clusters = 4\n",
        "data = corpus_embeddings\n",
        "kclusterer = KMeansClusterer(num_clusters, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
        "assigned_clusters = kclusterer.cluster(data, assign_clusters=True)\n",
        "\n",
        "print(assigned_clusters)\n",
        "print()\n",
        "\n",
        "clustered_sentences = [[] for i in range(num_clusters)]\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "for i, cluster in enumerate(clustered_sentences):\n",
        "    print(\"Cluster \", i+1)\n",
        "    print(cluster)\n",
        "    print(\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 2, 2, 2, 2, 1, 3]\n",
            "\n",
            "Cluster  1\n",
            "['這個服務生很不親切', '这个服务生很不亲切']\n",
            "\n",
            "Cluster  2\n",
            "['這個週末陽光普照!', '天朗氣清的星期天。']\n",
            "\n",
            "Cluster  3\n",
            "['黄昏時滂沱大雨', '放工時下大雨', '現時恒指已跌穿重要支持位26500點來看。']\n",
            "\n",
            "Cluster  4\n",
            "['港股繼續尋底的機會是頗高的。']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN48mFEPu5uc"
      },
      "source": [
        "# DBSCAN (distance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt0VZNrAWLj4",
        "outputId": "66e3de46-07d5-4d41-85c2-b7836f3be364"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "cluster = DBSCAN(eps=2.25,min_samples=1).fit(corpus_embeddings)\n",
        "cluster.labels_"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 2, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}