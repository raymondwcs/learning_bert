{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n",
    "model = AutoModel.from_pretrained('bert-base-chinese',output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Â§ö', 'Âîî', 'Â§ö', '‰∫∫', 'Áê¥', 'Êó•', 'ËøΩ', '129', '##9', 'ai', '##a', '„ÄÇ', 'ÈÄô', 'Èöª', 'Èáé', 'Â•Ω', 'Èõ£', 'Áé©', '10', 'Âπ¥', 'Âîî', 'È¨±', '‰∏Ä', 'È¨±', 'Â∞±', 'Âπæ', 'Âπ¥', 'Âçá', 'ÂπÖ', 'Ë°å', 'Êõ¨', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Â§öÂîîÂ§ö‰∫∫Áê¥Êó•ËøΩ1299 aia„ÄÇÈÄôÈöªÈáéÂ•ΩÈõ£Áé© 10Âπ¥ÂîîÈ¨± ‰∏ÄÈ¨±Â∞±ÂπæÂπ¥ÂçáÂπÖË°åÊõ¨ ü§Æ\"\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1914, 1540, 1914, 782, 4433, 3189, 6841, 8990, 8160, 8578, 8139, 511, 6857, 7407, 7029, 1962, 7432, 4381, 8108, 2399, 1540, 7786, 671, 7786, 2218, 2407, 2399, 1285, 2388, 6121, 3287, 100]\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â§ö\n",
      "Âîî\n",
      "Â§ö\n",
      "‰∫∫\n",
      "Áê¥\n",
      "Êó•\n",
      "ËøΩ\n",
      "129\n",
      "##9\n",
      "ai\n",
      "##a\n",
      "„ÄÇ\n",
      "ÈÄô\n",
      "Èöª\n",
      "Èáé\n",
      "Â•Ω\n",
      "Èõ£\n",
      "Áé©\n",
      "10\n",
      "Âπ¥\n",
      "Âîî\n",
      "È¨±\n",
      "‰∏Ä\n",
      "È¨±\n",
      "Â∞±\n",
      "Âπæ\n",
      "Âπ¥\n",
      "Âçá\n",
      "ÂπÖ\n",
      "Ë°å\n",
      "Êõ¨\n",
      "[UNK]\n",
      "Â§ö Âîî Â§ö ‰∫∫ Áê¥ Êó• ËøΩ 1299 aia „ÄÇ ÈÄô Èöª Èáé Â•Ω Èõ£ Áé© 10 Âπ¥ Âîî È¨± ‰∏Ä È¨± Â∞± Âπæ Âπ¥ Âçá ÂπÖ Ë°å Êõ¨ [UNK]\n"
     ]
    }
   ],
   "source": [
    "for token in indexed_tokens:\n",
    "    print(tokenizer.convert_ids_to_tokens(token))\n",
    "\n",
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option direction\n",
      "{'input_ids': tensor([[ 101, 1914, 1540, 1914,  782, 4433, 3189, 6841, 8990, 8160, 8578, 8139,\n",
      "          511, 6857, 7407, 7029, 1962, 7432, 4381, 8108, 2399, 1540, 7786,  671,\n",
      "         7786, 2218, 2407, 2399, 1285, 2388, 6121, 3287,  100,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rso/Applications/miniforge3/envs/nlp/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(text,return_tensors='pt',max_length=80,truncation=True,pad_to_max_length=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 80\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "hidden_states = outputs[2]\n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 2769, 4433, 3189, 1343, 1477, 6121, 6125,  102],\n",
      "        [ 101, 2492, 4433,  913, 2769, 1646, 5646, 6637,  102],\n",
      "        [ 101, 2769, 4433, 3189, 1343, 1477, 6121, 6125,  102]])\n"
     ]
    }
   ],
   "source": [
    "sentences = ['ÊàëÁê¥Êó•ÂéªÂíóË°åË°ó','ÂΩàÁê¥‰øÇÊàëÂòÖËààË∂£','ÊàëÁê¥Êó•ÂéªÂíóË°åË°ó']\n",
    "\n",
    "tokens = tokenizer(sentences,return_tensors='pt')\n",
    "print(tokens.input_ids)\n",
    "outputs = model(**tokens)\n",
    "hidden_states = outputs[2]   # 13 x 3 x len(sentence) x 768\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def idx(tokens,x):\n",
    "    X = tokenizer.convert_ids_to_tokens(tokens)\n",
    "    return X.index(x)\n",
    "\n",
    "print(idx(tokens.input_ids[0],'Áê¥'))\n",
    "print(idx(tokens.input_ids[1],'Áê¥'))\n",
    "\n",
    "layer_i = 12\n",
    "sentence_1 = 0\n",
    "sentence_2 = 1\n",
    "sentence_3 = 2\n",
    "embeddings_1 = hidden_states[layer_i][sentence_1][idx(tokens.input_ids[sentence_1],'Áê¥')]\n",
    "embeddings_2 = hidden_states[layer_i][sentence_2][idx(tokens.input_ids[sentence_2],'Áê¥')]\n",
    "embeddings_3 = hidden_states[layer_i][sentence_3][idx(tokens.input_ids[sentence_3],'Áê¥')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(list(embeddings_1.detach().numpy()) == list(embeddings_3.detach().numpy()))\n",
    "print(list(embeddings_1.detach().numpy()) == list(embeddings_2.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAI/CAYAAAC4QOfKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAV2ElEQVR4nO3db4xl913f8c+33sDwR2xseW2ZONsLkpUmiiBBI5Q2CCGcqG4dxX4SNaxAq5JoVQloqEAwoQ86PEBaqRUKDxCSFUJWShwUQaitDP/MQkQrQeg6AZLUgCM6BNPFa0IxFGRQyq8P5q69Ozvjne/szJw7M6+XtLr3nHt3z1fHXt+3z71zfzXGCAAAO/dPph4AAOCwEVAAAE0CCgCgSUABADQJKACAJgEFANB04iAPduedd47ZbHaQhwQA2JUnn3zyL8YYp7Z67EADajab5dKlSwd5SACAXamqP9nuMW/hAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAHQOzlbXMVtamHgMAjgwBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0CahjarayltnKWvsxAEBAAQC0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAph0HVFXdVlWfrqqPz7fvqKonqurp+e3t+zcmAMDi6FyBek+Sp67ZXklycYxxX5KL820AgCNvRwFVVfcmeTDJ+6/Z/VCSC/P7F5I8vKeTAQAsqJ1egXpfkh9K8o/X7Lt7jHE5Sea3d+3taAAAi+mmAVVVb0tyZYzx5G4OUFXnqupSVV167rnndvNHAAAslJ1cgXpzkrdX1XqSn03y7VX1oSTPVtU9STK/vbLVbx5jPDLGWB5jLJ86dWqPxgYAmM5NA2qM8d4xxr1jjFmSdyb59THGdyZ5PMnZ+dPOJnls36YEAFggt/I9UOeTvLWqnk7y1vk2AMCRd6Lz5DHGJ5J8Yn7/i0nu3/uRAAAWm28iBwBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQLEjs5W1zFbWph4DABaCgAIAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATSemHoCDM1tZ29VjAMD1XIECAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUAdMbOVNevaAcA+E1AAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0nZh6ABbXtmvqrZ6c3z5/cMMAwAJxBQoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgDrG1pfOJKsnpx4DAA4dAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADTdNKCqaqmqfqeqfq+qPldVPzrff0dVPVFVT89vb9//cQEApreTK1B/n+TbxxjfmOQNSR6oqjclWUlycYxxX5KL820AgCPvpgE1Nvzf+eYr5r9GkoeSXJjvv5Dk4f0YEABg0ezoM1BVdVtV/W6SK0meGGN8MsndY4zLSTK/vWvfpgQAWCAndvKkMcb/S/KGqnplkl+oqtfv9ABVdS7JuSQ5ffr0bmZkj60vnZl6BAA41Fo/hTfG+Kskn0jyQJJnq+qeJJnfXtnm9zwyxlgeYyyfOnXq1qYFAFgAO/kpvFPzK0+pqq9I8pYkf5Dk8SRn5087m+SxfZoRAGCh7OQtvHuSXKiq27IRXB8dY3y8qn4ryUer6l1JvpDkHfs4JwDAwrhpQI0xfj/JG7fY/8Uk9+/HUAAAi8w3kQMANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE07WguPw+1ma9/NVtYOaBIAOBpcgQIAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATZZyYV9cuzzM+vkHJ5wEAPaeK1AAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0WQuPba0vnUmSzF549GWfZ907AI4bV6AAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoshYee2Z96UyyevO18wDgsHMFCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0CSgAgCZr4bFrs5W1qUcAgEm4AgUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgTUUbJ6MutLZ/b1EJZvAQABBQDQJqAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAOiRmK2v7vg7d+tKZ/VlLb/Xkxi8AOCIEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0nph6Aw2PzOnlXt2cvPDrFOAAwGVegAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaLIW3iE2W1lLkqyff3DSOTavkbedq/Mm088MALfCFSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATTcNqKp6dVX9RlU9VVWfq6r3zPffUVVPVNXT89vb939cAIDp7eQK1JeS/MAY47VJ3pTke6rqdUlWklwcY9yX5OJ8GwDgyLtpQI0xLo8xPjW//zdJnkryqiQPJbkwf9qFJA/v04wAAAul9RmoqpoleWOSTya5e4xxOdmIrCR37fl0AAALaMdLuVTVVyf5+STfP8b466ra6e87l+Rckpw+fXo3M7KNq0uozFYenW9POQ0AHB87ugJVVa/IRjx9eIzxsfnuZ6vqnvnj9yS5stXvHWM8MsZYHmMsnzp1ai9mBgCY1E5+Cq+S/HSSp8YYP37NQ48nOTu/fzbJY3s/HgDA4tnJW3hvTvJdST5TVb873/cjSc4n+WhVvSvJF5K8Y18mBABYMDcNqDHGf0+y3Qee7t/bcQAAFp9vIgcAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJp2vBYe01tfOpOsJll9fupR9sxsZe3F++vnH5xwEgDYOVegAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaLIW3gK7dp24rfavL+3PcdeXzrzs9q3+ubMXHt2TPw8ApuIKFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE3WwjuC1pfOJKtJVp/f+fMBgB1zBQoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAma+EdYbOVtSTJ+tLBHvfq2nqzFx492AMDwAFxBQoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANNUY48AOtry8PC5dunRgxzvsri7FctXVJVIOu6tLvGy35Mv6+QcPfCYA2KyqnhxjLG/1mCtQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAmoRbF6cuMXALDwBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAmpRrZ7M+tKZqacAALYgoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGg6MfUAHD/W+APgsHMFCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoElAAQA0CagFNFtZe/H++tIZS58AwIIRUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQNNNA6qqPlBVV6rqs9fsu6Oqnqiqp+e3t+/vmAAAi2MnV6A+mOSBTftWklwcY9yX5OJ8GwDgWLhpQI0xfjPJX27a/VCSC/P7F5I8vLdjAQAsrt1+BuruMcblJJnf3rV3IwEALLYT+32AqjqX5FySnD59er8Pd/itnsz60o27j9N6eNetBXj+wQknAYCt7fYK1LNVdU+SzG+vbPfEMcYjY4zlMcbyqVOndnk4AIDFsduAejzJ2fn9s0ke25txAAAW306+xuAjSX4ryWuq6pmqeleS80neWlVPJ3nrfBsA4Fi46Wegxhjfsc1D9+/xLAAAh4JvIgcAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCg6cTUAxw5qyfnt8/vaHu2spYkWV86qAGPgNWTL51PAJiAK1AAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABNAgoAoMlSLntotrK24yVZXlrC5cw+TnS4rS+dSVbz8su2bF4qBwAOgCtQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANFkLb5+8tNbd1o9bA297W52bjXUGX+acWRMPgAPkChQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmgQUAECTgAIAaBJQAABN1sLbK6snt1337urjbG1X6wI6nwBMyBUoAIAmAQUA0CSgAACaBBQAQJOAAgBoElAAAE0CCgCgSUABADQJKACAJgEFANAkoAAAmqyFt092tb4bW7vZOoMAcMBcgQIAaBJQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKDJWni7tXoySTJ74dGsn39w4mHYymxlLUn88wFgz7kCBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaLOXS9OLyIEvX77t2mwWwejLrSxtL7dzsede6YWmeq4+vPr/HAwJwmLkCBQDQJKAAAJoEFABAk4ACAGgSUAAATQIKAKBJQAEANAkoAIAmAQUA0CSgAACaBBQAQFONMQ7sYMvLy+PSpUv7e5Dt1i7bvH++fXWttBfXP9u0NhokufW18Lb7943FYu3Do80/30Pv6nq0ycH8d7SqnhxjLG/1mCtQAABNAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABA0y0FVFU9UFV/WFWfr6qVvRoKAGCR7Tqgquq2JD+Z5F8leV2S76iq1+3VYAAAi+pWrkB9c5LPjzH+eIzxD0l+NslDezMWAMDiupWAelWSP71m+5n5PgCAI23Xa+FV1TuS/Msxxrvn29+V5JvHGN+36Xnnkpybb74myR/uftx9cWeSv5h6iAXifNzIObmRc3I95+NGzsn1nI8bHYZz8k/HGKe2euDELfyhzyR59TXb9yb535ufNMZ4JMkjt3CcfVVVl7ZbKPA4cj5u5JzcyDm5nvNxI+fkes7HjQ77ObmVt/D+R5L7qurrqurLkrwzyeN7MxYAwOLa9RWoMcaXqup7k/xKktuSfGCM8bk9mwwAYEHdylt4GWP8YpJf3KNZprKwby9OxPm4kXNyI+fkes7HjZyT6zkfNzrU52TXHyIHADiuLOUCANB07AOqqv5zVf1BVf1+Vf1CVb1y6pmmYmme61XVq6vqN6rqqar6XFW9Z+qZFkFV3VZVn66qj089yyKoqldW1c/N/zvyVFX986lnmlJV/Yf535fPVtVHqmpp6pkOWlV9oKquVNVnr9l3R1U9UVVPz29vn3LGg7bNOTnUr7/HPqCSPJHk9WOMb0jyR0neO/E8k7A0z5a+lOQHxhivTfKmJN/jnCRJ3pPkqamHWCA/keSXxxj/LMk35hifm6p6VZJ/n2R5jPH6bPyA0TunnWoSH0zywKZ9K0kujjHuS3Jxvn2cfDA3npND/fp77ANqjPGrY4wvzTd/OxvfZ3UcWZpnkzHG5THGp+b3/yYbL4zH+tv2q+reJA8mef/UsyyCqvqaJN+a5KeTZIzxD2OMv5p0qOmdSPIVVXUiyVdmi+8HPOrGGL+Z5C837X4oyYX5/QtJHj7Imaa21Tk57K+/xz6gNvnuJL809RATsTTPy6iqWZI3JvnkxKNM7X1JfijJP048x6L4+iTPJfmZ+dua76+qr5p6qKmMMf4syX9J8oUkl5M8P8b41WmnWhh3jzEuJxv/c5bkronnWTSH7vX3WARUVf3a/P34zb8euuY5/zEbb9l8eLpJJ1Vb7PMjmkmq6quT/HyS7x9j/PXU80ylqt6W5MoY48mpZ1kgJ5J8U5KfGmO8Mcnf5vi9NfOi+ed6HkrydUm+NslXVdV3TjsVi+6wvv7e0vdAHRZjjLe83ONVdTbJ25LcP47v9zrsaGme46aqXpGNePrwGONjU88zsTcneXtV/eskS0m+pqo+NMY4zi+QzyR5Zoxx9crkz+UYB1SStyT5X2OM55Kkqj6W5F8k+dCkUy2GZ6vqnjHG5aq6J8mVqQdaBIf59fdYXIF6OVX1QJIfTvL2McbfTT3PhCzNs0lVVTY+2/LUGOPHp55namOM944x7h1jzLLx78evH/N4yhjjz5P8aVW9Zr7r/iT/c8KRpvaFJG+qqq+c//25P8f4Q/WbPJ7k7Pz+2SSPTTjLQjjsr7/H/os0q+rzSb48yRfnu357jPHvJhxpMvMrC+/LS0vz/Ni0E02rqr4lyX9L8pm89JmfH5l/A/+xVlXfluQHxxhvm3iUyVXVG7LxofovS/LHSf7tGOP/TDrUhKrqR5P8m2y8JfPpJO8eY/z9tFMdrKr6SJJvS3JnkmeT/Kck/zXJR5OczkZovmOMsfmD5kfWNufkvTnEr7/HPqAAALqO/Vt4AABdAgoAoElAAQA0CSgAgCYBBQDQJKAAAJoEFABAk4ACAGj6/3gesusTD032AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(embeddings_1.detach().numpy(), bins=200)\n",
    "plt.hist(embeddings_2.detach().numpy(), bins=200)\n",
    "# plt.hist(embeddings_3.detach().numpy(), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ae98c631e394dd92bf870df93f8145d8d936f3b9b0948ebeb4ec1e7a1cff192"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
